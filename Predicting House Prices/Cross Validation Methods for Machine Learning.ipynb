{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Predicting House Prices with Linear Regression project, I talked a little bit about model evaluation. Specifically, I talked about cross validation. I want to expand on this topic.\n",
    "\n",
    "\n",
    "\n",
    "Let's assume this dataset has been fully cleaned and processed. We are interested in using a linear regression model on this dataset. However, we need a way to evaluate this model's performance.\n",
    "\n",
    "Specifically, we need to know how well this model will perform with new data. The best way to investigate this idea is to use an example. I've exported my previous project into csv file named \"AmesHousinFinal.csv\". \n",
    "\n",
    "Starting with imports and a brief look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1570, 87)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>years_to_sell</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Garage Yr Blt</th>\n",
       "      <th>...</th>\n",
       "      <th>MS SubClass_60</th>\n",
       "      <th>MS SubClass_70</th>\n",
       "      <th>MS SubClass_75</th>\n",
       "      <th>MS SubClass_80</th>\n",
       "      <th>MS SubClass_85</th>\n",
       "      <th>MS SubClass_90</th>\n",
       "      <th>MS SubClass_120</th>\n",
       "      <th>MS SubClass_160</th>\n",
       "      <th>MS SubClass_180</th>\n",
       "      <th>MS SubClass_190</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215000</td>\n",
       "      <td>6</td>\n",
       "      <td>1656</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105000</td>\n",
       "      <td>5</td>\n",
       "      <td>896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>49</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172000</td>\n",
       "      <td>6</td>\n",
       "      <td>1329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>52</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>1</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244000</td>\n",
       "      <td>7</td>\n",
       "      <td>2110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>42</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>2</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195500</td>\n",
       "      <td>6</td>\n",
       "      <td>1604</td>\n",
       "      <td>2.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>12</td>\n",
       "      <td>926.0</td>\n",
       "      <td>926</td>\n",
       "      <td>2</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice  Overall Qual  Gr Liv Area  Garage Cars  Garage Area  \\\n",
       "0     215000             6         1656          2.0        528.0   \n",
       "1     105000             5          896          1.0        730.0   \n",
       "2     172000             6         1329          1.0        312.0   \n",
       "3     244000             7         2110          2.0        522.0   \n",
       "4     195500             6         1604          2.0        470.0   \n",
       "\n",
       "   years_to_sell  Total Bsmt SF  1st Flr SF  Full Bath  Garage Yr Blt  ...  \\\n",
       "0             50         1080.0        1656          1         1960.0  ...   \n",
       "1             49          882.0         896          1         1961.0  ...   \n",
       "2             52         1329.0        1329          1         1958.0  ...   \n",
       "3             42         2110.0        2110          2         1968.0  ...   \n",
       "4             12          926.0         926          2         1998.0  ...   \n",
       "\n",
       "   MS SubClass_60  MS SubClass_70  MS SubClass_75  MS SubClass_80  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               1               0               0               0   \n",
       "\n",
       "   MS SubClass_85  MS SubClass_90  MS SubClass_120  MS SubClass_160  \\\n",
       "0               0               0                0                0   \n",
       "1               0               0                0                0   \n",
       "2               0               0                0                0   \n",
       "3               0               0                0                0   \n",
       "4               0               0                0                0   \n",
       "\n",
       "   MS SubClass_180  MS SubClass_190  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                0  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"AmesHousingFinal.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Holdout Validation\n",
    "\n",
    "We are interested in creating a model that can predict the \"Sale Price\" with the features given in data. The first method is to slice up our dataset into two parts:\n",
    "\n",
    "+ A training set to fit the model.\n",
    "+ A testing set to predict our results.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src = \"images/cross-validation/method1.PNG\"\n",
    "alt=\"holdout validation diagram\"/>\n",
    "</div>\n",
    "\n",
    "We can then compare the predictions from the testing set with the actual data using RMSE as the error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\n",
      "28749.561761555196\n"
     ]
    }
   ],
   "source": [
    "#93% of the data as training set\n",
    "train = data[0:1460]\n",
    "test = data[1460:]\n",
    "features = data.columns.drop(['SalePrice'])\n",
    "\n",
    "#train\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "#predict\n",
    "predictions = lr.predict(test[features])\n",
    "rmse = mean_squared_error(test['SalePrice'], predictions)**0.5\n",
    "print('RMSE:')\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got ~28749 as our root mean squared error. But can we really use this value as a metric to evaluate our model? \n",
    "\n",
    "What happens if we shuffle the dataset arround? We would get a brand new RMSE value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 29156.98404803793,\n",
       " 1: 29005.494913308787,\n",
       " 2: 26306.49717295175,\n",
       " 3: 32018.8213594359,\n",
       " 4: 31543.21579269828,\n",
       " 5: 66453.98446604444,\n",
       " 6: 35640.22774097788,\n",
       " 7: 34044.8040887492,\n",
       " 8: 28225.124902220443,\n",
       " 9: 39500.73574601386}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seeds = {}\n",
    "for i in range(10):\n",
    "    np.random.seed(i)\n",
    "    randomed_index = np.random.permutation(data.index)\n",
    "    randomed_df = data.reindex(randomed_index)\n",
    "\n",
    "    train = randomed_df[0:1460]\n",
    "    test = randomed_df[1460:]\n",
    "    features = randomed_df.columns.drop(['SalePrice'])\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "    predictions = lr.predict(test[features])\n",
    "    rmse = mean_squared_error(test['SalePrice'], predictions)**0.5\n",
    "    random_seeds[i]=rmse\n",
    "random_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above is a dictionary with random seeds as the keys and RMSE as the values. We are getting drastically different RMSE values depending on how we slice up our data. \n",
    "\n",
    "So how do we know if the model is actually good at predicting new data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: K-Fold Cross Validation\n",
    "\n",
    "This is where cross validation is really useful. Suppose we split the data set into four blocks (K = 4). We can train four linear regression models with each block being the test set once. The rest of the data will be the training set.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src = images/cross-validation/Kfold.PNG\n",
    "alt=\"K-Fold Cross validation Diagram\" style=\"width:800px;\"/>\n",
    "</div>\n",
    "\n",
    "Each one of these model will have its own error, in our this case this error will be the RMSE. We can evaluate the model based on the average error from the four models. This method is useful because we are eliminating some of the selection bias. In the first method, only part of the data end up as the training set. In cross validation, all of the data end up in both the training set and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE from the four models:\n",
      "[30916.82796137624, 31938.177268887655, 41078.25075425058, 36185.8346785463]\n",
      "----\n",
      "Average RMSE:\n",
      "35029.772665765195\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state = 7)\n",
    "\n",
    "rmse_list = []\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[test_index]\n",
    "    features = data.columns.drop(['SalePrice'])\n",
    "    \n",
    "    #train\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "        \n",
    "    #predict    \n",
    "    predictions = lr.predict(test[features])\n",
    "        \n",
    "    rmse = mean_squared_error(test['SalePrice'], predictions)**0.5\n",
    "    rmse_list.append(rmse)\n",
    "print('RMSE from the four models:')\n",
    "print(rmse_list)\n",
    "print('----')\n",
    "print('Average RMSE:')\n",
    "print(np.mean(rmse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Leave One Out Validation\n",
    "\n",
    "So what happens if we take K to the extreme, and set K = n. Where n is the number of rows in a dataset. We are going to train n number of models. Each one of these models will have one row as the testing set, and the rest of the data as the training set.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "<img src = images/cross-validation/leaveoneout.PNG\n",
    "alt=\"Leave One Out Validation Diagram\" style=\"width:800px;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "We generate n number of models. Each one of these models will use every single row except for one row as the training set. Then we'll test the model with the row that was not a part of the training set. Finally, we check the error of this model. \n",
    "\n",
    "This process gets repeated until all of the rows in our dataset get tested. Once that is complete, we can compute the average error to see how well the model performed.\n",
    "\n",
    "The biggest drawback to this method is the computation time. We can use the time module from python to determine how long it takes to complete the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time:\n",
      "15.32140150755418 seconds\n",
      "----\n",
      "Average RMSE:\n",
      "21428.449121978723\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=len(data), shuffle=True, random_state = 7)\n",
    "rmse_list = []\n",
    "\n",
    "time_start = time.clock()\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[test_index]\n",
    "    features = data.columns.drop(['SalePrice'])\n",
    "    \n",
    "    #train\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "        \n",
    "    #predict    \n",
    "    predictions = lr.predict(test[features])\n",
    "        \n",
    "    rmse = mean_squared_error(test['SalePrice'], predictions)**0.5\n",
    "    rmse_list.append(rmse)    \n",
    "time_stop = time.clock()\n",
    "\n",
    "print('Processing time:')\n",
    "print(str(time_stop-time_start) + ' seconds')\n",
    "print('----')\n",
    "print('Average RMSE:')\n",
    "print(np.mean(rmse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took my computer about 28 seconds to generate 1570 models and computing the error, which isn't so bad. This can get very time consuming/expensive if we had a very large dataset.\n",
    "\n",
    "### Average RMSE as K approaches n\n",
    "\n",
    "Let's see what happens if we plot all of this out. I've decided to measure the average RMSE from k=2 to k=1502 at intervals of 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time:\n",
      "125.91830799470496 seconds\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "\n",
    "rmse_kfolds = []\n",
    "for i in range(2, len(data),100):\n",
    "    kf = KFold(n_splits=i, shuffle=True, random_state = 7)\n",
    "    rmse_list = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train = data.iloc[train_index]\n",
    "        test = data.iloc[test_index]\n",
    "        features = data.columns.drop(['SalePrice'])\n",
    "    \n",
    "        #train\n",
    "        lr.fit(train[features], train['SalePrice'])\n",
    "        \n",
    "        #predict    \n",
    "        predictions = lr.predict(test[features])\n",
    "        \n",
    "        rmse = mean_squared_error(test['SalePrice'], predictions)**0.5\n",
    "        rmse_list.append(rmse)\n",
    "    rmse_kfolds.append(np.mean(rmse_list))\n",
    "time_stop = time.clock()\n",
    "\n",
    "print('Processing time:')\n",
    "print(str(time_stop-time_start) + ' seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = [i for i in range(2, len(data),100)]\n",
    "y = rmse_kfolds \n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Kfolds')\n",
    "plt.ylabel('Average RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Verdict\n",
    "\n",
    "As we increase the number of Kfolds, the average RMSE goes down. Does that mean we should maximize the number of KFolds each time? No!\n",
    "\n",
    "Cross validation is a model evaluation technique. We use different estimators such as linear regression, KNN, random forests etc. Then we evaluate the error on each estimator. \n",
    "\n",
    "With a small number of KFolds, such as K = 2:\n",
    "+ Computation time will be low\n",
    "+ Variance of the estimator will be low\n",
    "+ Bias of the estimator will be high (underfitting)\n",
    "\n",
    "With a large number of KFolds as K approachs n:\n",
    "+ Computation time will be high\n",
    "+ Bias of the estimator will be low\n",
    "+ Variance of the estimator will be high (overfitting)\n",
    "\n",
    "While the computational time is a concern, it is not the only thing we should worry about. For K = n, all the models will be similar, because we are only leaving one row out of the training set. This is great for lowering selection bias. Even though we generated n number of models, it is possible for all these models to be highly inaccurate. For more information on bias/variance click [here](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) for the wikipedia page.\n",
    "\n",
    "To further explore this idea, let's take a look at what happens when we test our linear regression model with the same data as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\n",
      "30506.455820900163\n"
     ]
    }
   ],
   "source": [
    "#100% of the data as training set\n",
    "train = data\n",
    "\n",
    "#100% of the data as the test set\n",
    "test = data\n",
    "\n",
    "features = data.columns.drop(['SalePrice'])\n",
    "\n",
    "#train\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "#predict\n",
    "predictions = lr.predict(test[features])\n",
    "rmse = mean_squared_error(test['SalePrice'], predictions)**0.5\n",
    "print('RMSE:')\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the same data for both the testing set and the training set, overfitting is a problem. As a result, this model is specific to the dataset. We got a RMSE value of 30506.\n",
    "\n",
    "We got an average RMSE value of 21428 from the leave one out validation method. So it is pretty clear that overfitting is an even greater problem in this case.\n",
    "\n",
    "In practice, the number of folds we should use depends on the dataset. If we have a small dataset, say ~500 rows and we use K = 2. The models will only have 250 rows as the training set. If we have a large dataset, say ~500,000 rows then using K = 2 might be acceptable.\n",
    "\n",
    "Most academic research papers use K = 10, but keep in mind their datasets are generally small. If we are working with big data, computation time becomes a problem. If that is the case, we should consider using a lower K value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
