{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f24398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 11.999999999999998\n",
      "Prediction Interval (at 95.0% confidence): (6.202241812562375, 17.797758187437623)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace this with your dataset)\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make a prediction on a test instance\n",
    "test_instance = np.array([[6]])\n",
    "prediction = regressor.predict(test_instance)[0]\n",
    "\n",
    "# Calculate the prediction interval with a user-defined confidence level (e.g., 95%)\n",
    "confidence_level = 0.95\n",
    "prediction_interval = (prediction - np.std(y_train) * 1.96, prediction + np.std(y_train) * 1.96)\n",
    "\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Prediction Interval (at {confidence_level*100}% confidence): {prediction_interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67aeaa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Instance: 2, Prediction Interval: [2.0000000000000018, 6.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace this with your dataset)\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Define a nonconformity measure function (simple absolute difference in this case)\n",
    "def nonconformity_measure(y_true, y_pred):\n",
    "    return np.abs(y_true - y_pred)\n",
    "\n",
    "# Initialize the list to store prediction intervals\n",
    "prediction_intervals = []\n",
    "\n",
    "# Perform ICP for each test instance\n",
    "for test_instance, true_value in zip(X_test, y_test):\n",
    "    # Make a prediction on the test instance\n",
    "    prediction = regressor.predict(test_instance.reshape(1, -1))[0]\n",
    "    \n",
    "    # Calculate nonconformity score for the test instance\n",
    "    nc_score = nonconformity_measure(true_value, prediction)\n",
    "    \n",
    "    # Find the k-th smallest nonconformity score from the training set (k = 1 for ICP)\n",
    "    k = 1\n",
    "    k_smallest_nc = np.partition(nonconformity_measure(y_train, prediction), k-1)[k-1]\n",
    "    \n",
    "    # Calculate the p-value (proportion of training instances with nonconformity score >= k_smallest_nc)\n",
    "    p_value = np.sum(nonconformity_measure(y_train, prediction) >= k_smallest_nc) / len(y_train)\n",
    "    \n",
    "    # Define the significance level (1 - confidence level)\n",
    "    confidence_level = 0.95\n",
    "    significance = 1 - confidence_level\n",
    "    \n",
    "    # Calculate the prediction interval based on the p-value and significance level\n",
    "    lower_bound = prediction - k_smallest_nc if p_value > significance else prediction\n",
    "    upper_bound = prediction + k_smallest_nc if p_value > significance else prediction\n",
    "    \n",
    "    prediction_intervals.append((lower_bound, upper_bound))\n",
    "\n",
    "# Print the prediction intervals for each test instance\n",
    "for idx, test_instance in enumerate(X_test):\n",
    "    lower_bound, upper_bound = prediction_intervals[idx]\n",
    "    print(f\"Test Instance: {test_instance[0]}, Prediction Interval: [{lower_bound}, {upper_bound}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2414107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Instance: 2, Prediction Interval: [2.0000000000000018, 6.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def inductive_conformal_prediction(X_train, y_train, X_test, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Perform Inductive Conformal Prediction for regression tasks.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (numpy.ndarray): Training feature data.\n",
    "        y_train (numpy.ndarray): Training target data.\n",
    "        X_test (numpy.ndarray): Test feature data.\n",
    "        confidence_level (float): Desired confidence level (default is 0.95).\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples, each containing the lower and upper bounds of the prediction intervals\n",
    "              for each test instance.\n",
    "    \"\"\"\n",
    "    # Create and train a linear regression model\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Define a nonconformity measure function (simple absolute difference in this case)\n",
    "    def nonconformity_measure(y_true, y_pred):\n",
    "        return np.abs(y_true - y_pred)\n",
    "\n",
    "    # Initialize the list to store prediction intervals\n",
    "    prediction_intervals = []\n",
    "\n",
    "    # Perform ICP for each test instance\n",
    "    for test_instance in X_test:\n",
    "        # Make a prediction on the test instance\n",
    "        prediction = regressor.predict(test_instance.reshape(1, -1))[0]\n",
    "\n",
    "        # Calculate nonconformity score for the test instance\n",
    "        nc_score = nonconformity_measure(y_train, prediction)\n",
    "\n",
    "        # Find the k-th smallest nonconformity score from the training set (k = 1 for ICP)\n",
    "        k = 1\n",
    "        k_smallest_nc = np.partition(nonconformity_measure(y_train, prediction), k-1)[k-1]\n",
    "\n",
    "        # Calculate the p-value (proportion of training instances with nonconformity score >= k_smallest_nc)\n",
    "        p_value = np.sum(nonconformity_measure(y_train, prediction) >= k_smallest_nc) / len(y_train)\n",
    "\n",
    "        # Define the significance level (1 - confidence level)\n",
    "        significance = 1 - confidence_level\n",
    "\n",
    "        # Calculate the prediction interval based on the p-value and significance level\n",
    "        lower_bound = prediction - k_smallest_nc if p_value > significance else prediction\n",
    "        upper_bound = prediction + k_smallest_nc if p_value > significance else prediction\n",
    "\n",
    "        prediction_intervals.append((lower_bound, upper_bound))\n",
    "    \n",
    "    return prediction_intervals\n",
    "\n",
    "# Sample data (replace this with your dataset)\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform Inductive Conformal Prediction\n",
    "prediction_intervals = inductive_conformal_prediction(X_train, y_train, X_test)\n",
    "\n",
    "# Print the prediction intervals for each test instance\n",
    "for idx, test_instance in enumerate(X_test):\n",
    "    lower_bound, upper_bound = prediction_intervals[idx]\n",
    "    print(f\"Test Instance: {test_instance[0]}, Prediction Interval: [{lower_bound}, {upper_bound}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d246acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def absolute_difference_nonconformity_measure(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Simple nonconformity measure based on the absolute difference between true and predicted target values.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (numpy.ndarray): True target values.\n",
    "        y_pred (numpy.ndarray): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of nonconformity scores for each instance.\n",
    "    \"\"\"\n",
    "    return np.abs(y_true - y_pred)\n",
    "\n",
    "def inductive_conformal_prediction(X_train, y_train, X_test, confidence_level=0.95):\n",
    "    # ... (same as the previous implementation)\n",
    "    # Rest of the code remains the same...\n",
    "    # ... (same as the previous implementation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce97a35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sequence: [10 15 20], Prediction Interval: [0. 0.]\n",
      "Test Sequence: [15 20 25], Prediction Interval: [20. 20.]\n",
      "Test Sequence: [20 25 30], Prediction Interval: [25. 25.]\n",
      "Test Sequence: [25 30 35], Prediction Interval: [30. 30.]\n",
      "Test Sequence: [30 35 40], Prediction Interval: [35. 35.]\n",
      "Test Sequence: [35 40 45], Prediction Interval: [40. 40.]\n",
      "Test Sequence: [40 45 50], Prediction Interval: [45. 45.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_time_series(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Convert time series data into overlapping sequences with the specified sequence length.\n",
    "    \n",
    "    Parameters:\n",
    "        data (numpy.ndarray): 1-D array of the time series data.\n",
    "        sequence_length (int): Length of the sequences to generate.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 2-D array of overlapping sequences.\n",
    "    \"\"\"\n",
    "    n_sequences = len(data) - sequence_length + 1\n",
    "    sequences = [data[i:i+sequence_length] for i in range(n_sequences)]\n",
    "    return np.array(sequences)\n",
    "\n",
    "def absolute_difference_nonconformity_measure(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Simple nonconformity measure based on the absolute difference between true and predicted target values.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (numpy.ndarray): True target values.\n",
    "        y_pred (numpy.ndarray): Predicted target values.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of nonconformity scores for each instance.\n",
    "    \"\"\"\n",
    "    return np.abs(y_true - y_pred)\n",
    "\n",
    "def markov_conformal_predictor(time_series, sequence_length, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Markov Conformal Predictor for univariate time series forecasting using autoregressive models.\n",
    "    \n",
    "    Parameters:\n",
    "        time_series (numpy.ndarray): 1-D array of the time series data.\n",
    "        sequence_length (int): Length of the sequences for autoregressive modeling.\n",
    "        confidence_level (float): Desired confidence level (default is 0.95).\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Array of tuples containing the lower and upper bounds of the prediction intervals\n",
    "                       for each test instance (sequence).\n",
    "    \"\"\"\n",
    "    # Split the time series into overlapping sequences\n",
    "    sequences = generate_time_series(time_series, sequence_length)\n",
    "    n_sequences = len(sequences)\n",
    "\n",
    "    # Initialize arrays to store the predicted values and nonconformity scores\n",
    "    predictions = np.zeros(n_sequences)\n",
    "    nonconformity_scores = np.zeros(n_sequences)\n",
    "\n",
    "    # Generate predictions and calculate nonconformity scores for each sequence\n",
    "    for i in range(n_sequences):\n",
    "        train_sequence = sequences[:i]\n",
    "        test_sequence = sequences[i:i+1]\n",
    "\n",
    "        if len(train_sequence) > 0:\n",
    "            # Train an autoregressive model (e.g., ARIMA) on the train_sequence\n",
    "            # Here, you may use any appropriate autoregressive model of your choice\n",
    "            \n",
    "            # For simplicity, we'll just use the last value of the train_sequence as the prediction\n",
    "            predictions[i] = train_sequence[-1][-1]\n",
    "\n",
    "            # Calculate the nonconformity score for the test_sequence\n",
    "            nonconformity_scores[i] = absolute_difference_nonconformity_measure(test_sequence[-1][-1], predictions[i])\n",
    "\n",
    "    # Find the k-th smallest nonconformity score from the training set (k = 1 for MCP)\n",
    "    k = 1\n",
    "    k_smallest_nc = np.partition(nonconformity_scores, k-1)[k-1]\n",
    "\n",
    "    # Calculate the p-value (proportion of training instances with nonconformity score >= k_smallest_nc)\n",
    "    p_values = (nonconformity_scores >= k_smallest_nc).astype(int) / n_sequences\n",
    "\n",
    "    # Define the significance level (1 - confidence level)\n",
    "    significance = 1 - confidence_level\n",
    "\n",
    "    # Calculate the prediction intervals based on the p-values and significance level\n",
    "    lower_bounds = predictions - k_smallest_nc * (p_values > significance)\n",
    "    upper_bounds = predictions + k_smallest_nc * (p_values > significance)\n",
    "\n",
    "    # Combine lower and upper bounds into prediction intervals\n",
    "    prediction_intervals = np.column_stack((lower_bounds, upper_bounds))\n",
    "    \n",
    "    return prediction_intervals\n",
    "\n",
    "# Sample time series data (replace this with your own time series)\n",
    "time_series = np.array([10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "\n",
    "# Set the sequence length for autoregressive modeling\n",
    "sequence_length = 3\n",
    "\n",
    "# Perform Markov Conformal Prediction\n",
    "confidence_level = 0.95\n",
    "prediction_intervals = markov_conformal_predictor(time_series, sequence_length, confidence_level)\n",
    "\n",
    "# Print the prediction intervals for each test instance (sequence)\n",
    "for idx, interval in enumerate(prediction_intervals):\n",
    "    print(f\"Test Sequence: {time_series[idx:idx+sequence_length]}, Prediction Interval: {interval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e18729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
